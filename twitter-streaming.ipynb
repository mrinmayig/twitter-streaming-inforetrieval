{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web-Scraping, Text-Mining and Information Retrieval using Twitter's Streamed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About this notebook: This is a project undertaken to get a hands-on experience with mining webscraped text data and perform information retrieval on data obtained from Twitter. I have streamed the data using Tweepy to obtain a text file with 3010 tweets. Extracted tutorial links relevant to top 3 programming languages namely: Python, JavaScript and Java.\n",
    "\n",
    "### Tags: Text-Mining, WebScraping, Tweepy, Twitter's Streaming API, Pandas, JSON, Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return True if a word is found in text, otherwise it returns False.\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    return True if match else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regular expressions for retrieving link that start with \"http://\" or https:// from a text.\n",
    "# Return the url if found, otherwise it returns an empty string.\n",
    "\n",
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract links from the text file saved by scraping twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON LINKS\n",
      "------------\n",
      "https://t.co/O2WOYFJ64z\n",
      "https://t.co/AAvrSS7lP6\n",
      "https://t.co/AAvrSS7lP6\n",
      "https://t.co/AAvrSS7lP6\n",
      "https://t.co/c2fmTm9Ixy\n",
      "https://t.co/b7qQLex7OC\n",
      "https://t.co/Ijrhr2LChd\n",
      "https://t.co/Ijrhr2LChd\n",
      "https://t.co/iDFJXjJSTW\n",
      "https://t.co/iDFJXjJSTW\n",
      "https://t.co/hn6UgxYpIO\n",
      "https://t.co/LrPBI3kjeI\n",
      "https://t.co/5bHZEyO9AL\n",
      "https://t.co/5bH…\n",
      "https://t.co/yPclZhC0wk\n",
      "https://t.co/aP8q7MobJS\n",
      "https://t.co/N49APvScA8\n",
      "https://t.co/VcyHafJ3Hv\n",
      "https://t.co/gyKVN4fG5e\n",
      "https://t.co/avby8I96iq\n",
      "https://t.co/mP90ORznvZ\n",
      "https://t.co/aP8q7MobJS\n",
      "https://t.co/eNVgaJNMun\n",
      "https://t.co/SM0p1HhaMK\n",
      "https://t.co/eyedP8wRD5\n",
      "https://t.co/jBdEJArmNx\n",
      "https://t.co/Fwyogyixkl\n",
      "https://t.co/uGNNF4bpF1\n",
      "https://t.co/WdZN35OAbf\n",
      "https://t.co/tBgiHBHTjQ\n",
      "https://t.co/SMaTayjFFA\n",
      "www.cyberforum.ru/python/thread2414680.html\n",
      "https://t.co/zYo5J1nwYc\n",
      "https://t.co/S5IeRPTWlT\n",
      "https://t.co/QRW1oDXN1w\n",
      "https://t.co/ZhoGbXRJGx\n",
      "https://t.co/FAmMiWCknl\n",
      "https://t.co/B7GQG72lqA\n",
      "https://t.co/epEEfWUfZy\n",
      "https://t.co/c7nzAy1vrX\n",
      "https://t.co/ACDU3TL3Fv\n",
      "https://t.co/M0lDAS9oTC\n",
      "https://t.co/6cVe3GveBj\n",
      "https://t.co/ACDU3TL3Fv\n",
      "https://t.co/5bH…\n",
      "https://t.co/5bH…\n",
      "https://t.co/nS7tVEJvm9\n",
      "https://t.co/NcvOcSM06y\n",
      "https://t.co/O87utaEwRw\n",
      "https://t.co/Orb1h4rmpl\n",
      "https://t.co/Orb1h4rmpl\n",
      "https://t.co/NNzumI98nu\n",
      "https://t.co/lZQmQJtxZe\n",
      "https://t.co/IJm8ELPdUI\n",
      "https://t.co/eZXkbTMh7u\n",
      "https://t.co/FHqRh7WnT0\n",
      "https://t.co/KGfFeZDkio\n",
      "https://t.co/ACDU3TL3Fv\n",
      "https://t.co/sqFl6Q0BNT\n",
      "Python links end here\n",
      "JAVASCRIPT LINKS\n",
      "----------------\n",
      "https://t.co/cnsZzBFpGH\n",
      "https://t.co/…\n",
      "https://t.co/Q20HZZOvb2\n",
      "https://t.co/KvH59SbBqJ\n",
      "https://t.co/GI3rmBzsAz\n",
      "https://t.co/5VFgBzYmRA\n",
      "https://t.co/q56AyKEsF2\n",
      "https://t.co/paNl1Sj2UG\n",
      "https://t.co/SIhXNA2lAg\n",
      "https://t.co/n7kV8C2V26\n",
      "https://t.co/N49APvScA8\n",
      "https://t.co/VcyHafJ3Hv\n",
      "https://t.co/gyKVN4fG5e\n",
      "https://t.co/avby8I96iq\n",
      "https://t.co/mP90ORznvZ\n",
      "https://t.co/wUmoQNU1mS\n",
      "https://t.co/brAcUQrI9h\n",
      "https://t.co/aXta5Iyzvj\n",
      "https://t.co/cdjyO30K8V\n",
      "https://t.co/TTuPw0a5Zg\n",
      "https://t.co/O6jthdvKME\n",
      "https://t.co/oLI1gw8EIb\n",
      "https://t.co/To3WZxZc3F\n",
      "https://t.co/AsEFJ3WpvE\n",
      "https://t.co/eKwwywlTQn\n",
      "https://t.co/tBgiHBHTjQ\n",
      "https://t.co/rGXZI5GTTz\n",
      "https://t.co/8lsDrHBeN2\n",
      "https://t.co/B7GQG72lqA\n",
      "https://t.co/YwDexgHAtw\n",
      "https://t.co/WDU6m5YI3m\n",
      "https://t.co/BuLvTplYXJ\n",
      "https://t.co/7x0a3QRNWj\n",
      "https://t.co/7x0a3QR…\n",
      "https://t.co/d7FXnIXIr0\n",
      "https://t.co/d7FXnIXIr0\n",
      "https://t.co/VpOxoTiMr9\n",
      "https://t.co/VpOxoTiMr9\n",
      "https://t.co/VpOxoTiMr9\n",
      "JavaScript links end here\n",
      "Java LINKS\n",
      "----------\n",
      "https://t.co/WXU6fj74Mr\n",
      "https://t.co/mwQryS7Nyr\n",
      "https://t.co/eAlgC6NaHX\n",
      "https://t.co/mwQryS7Nyr\n",
      "https://t.co/cnsZzBFpGH\n",
      "https://t.co/iDFJXjJSTW\n",
      "https://t.co/iDFJXjJSTW\n",
      "https://t.co/8wKriGagD6\n",
      "https://t.co/…\n",
      "https://t.co/Q20HZZOvb2\n",
      "https://t.co/KvH59SbBqJ\n",
      "https://t.co/GI3rmBzsAz\n",
      "https://t.co/5VFgBzYmRA\n",
      "https://t.co/q56AyKEsF2\n",
      "https://t.co/paNl1Sj2UG\n",
      "https://t.co/SIhXNA2lAg\n",
      "https://t.co/eAlgC6NaHX\n",
      "https://t.co/n7kV8C2V26\n",
      "https://t.co/N49APvScA8\n",
      "https://t.co/VcyHafJ3Hv\n",
      "https://t.co/gyKVN4fG5e\n",
      "https://t.co/avby8I96iq\n",
      "https://t.co/mP90ORznvZ\n",
      "https://t.co/wUmoQNU1mS\n",
      "https://t.co/brAcUQrI9h\n",
      "https://t.co/aXta5Iyzvj\n",
      "https://t.co/cdjyO30K8V\n",
      "https://t.co/TTuPw0a5Zg\n",
      "https://t.co/O6jthdvKME\n",
      "https://t.co/SM0p1HhaMK\n",
      "https://t.co/oLI1gw8EIb\n",
      "https://t.co/To3WZxZc3F\n",
      "https://t.co/AsEFJ3WpvE\n",
      "https://t.co/eKwwywlTQn\n",
      "https://t.co/tBgiHBHTjQ\n",
      "https://t.co/rGXZI5GTTz\n",
      "https://t.co/8lsDrHBeN2\n",
      "https://t.co/B7GQG72lqA\n",
      "https://t.co/YwDexgHAtw\n",
      "https://t.co/WDU6m5YI3m\n",
      "https://t.co/BuLvTplYXJ\n",
      "https://t.co/7x0a3QRNWj\n",
      "https://t.co/7x0a3QR…\n",
      "https://t.co/d7FXnIXIr0\n",
      "www.cyberforum.ru/java-j2se/thread2414686.html\n",
      "https://t.co/d7FXnIXIr0\n",
      "https://t.co/NcvOcSM06y\n",
      "https://t.co/VpOxoTiMr9\n",
      "https://t.co/VpOxoTiMr9\n",
      "https://t.co/VpOxoTiMr9\n",
      "Java links end here\n"
     ]
    }
   ],
   "source": [
    "#Main program to extract relevant tutorial links for Python, Javascript and Java\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the data in into an array that we call tweets.\n",
    "    tweets_data_path = 'twitter_data.txt'\n",
    "    tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "    tweets_data = [] #Empty array\n",
    "    for line in tweets_file:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            tweets_data.append(tweet) #Add tweets to the empty array that we created\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    #Create an empty DataFrame called tweets.\n",
    "    tweets = pd.DataFrame()\n",
    "\n",
    "    #Add text column to the tweets DataFrame, which contains the tweet.\n",
    "    tweets['text'] = list(map(lambda tweet: tweet['text'], tweets_data))\n",
    "\n",
    "    #Add 3 more columns.\n",
    "    tweets['python'] = tweets['text'].apply(lambda tweet: word_in_text('python', tweet))\n",
    "    tweets['javascript'] = tweets['text'].apply(lambda tweet: word_in_text('javascript', tweet))\n",
    "    tweets['java'] = tweets['text'].apply(lambda tweet: word_in_text('java', tweet))\n",
    "\n",
    "    #We are interested in targetting tweets that are related to programming\n",
    "    #languages, i.e. contains \"programming\" or \"tutorial\".\n",
    "    tweets['programming'] = tweets['text'].apply(lambda tweet: word_in_text('programming', tweet))\n",
    "    tweets['tutorial'] = tweets['text'].apply(lambda tweet: word_in_text('tutorial', tweet))\n",
    "\n",
    "    # Relevant if contains the word \"programming\" or \"tutorial\".\n",
    "    tweets['relevant'] = tweets['text'].apply(lambda tweet: word_in_text('programming', tweet) or word_in_text('tutorial', tweet))\n",
    "\n",
    "    #Contain the urls information.\n",
    "    tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))\n",
    "\n",
    "    # Create a new DataFrame called tweets_relevant_with_link. \n",
    "    tweets_relevant = tweets[tweets['relevant'] == True]\n",
    "    tweets_relevant_with_link = tweets_relevant[tweets_relevant['link'] != '']\n",
    "\n",
    "    #Print out all Python, JavaScript and Java links.\n",
    "    tweets_python = tweets_relevant_with_link[tweets_relevant_with_link['python'] == True]\n",
    "    tweets_javascript = tweets_relevant_with_link[tweets_relevant_with_link['javascript'] == True]\n",
    "    tweets_java = tweets_relevant_with_link[tweets_relevant_with_link['java'] == True]\n",
    "\n",
    "    python_links = tweets_python['link']\n",
    "    javascript_links = tweets_javascript['link']\n",
    "    java_links = tweets_java['link']\n",
    "\n",
    "    print(\"PYTHON LINKS\")\n",
    "    print(\"------------\")\n",
    "    for link in python_links:\n",
    "        print(link)\n",
    "    print(\"Python links end here\")\n",
    "    \n",
    "    print(\"JAVASCRIPT LINKS\")\n",
    "    print(\"----------------\")\n",
    "    for link in javascript_links:\n",
    "        print(link)\n",
    "    print(\"JavaScript links end here\")\n",
    "\n",
    "    print(\"Java LINKS\")\n",
    "    print(\"----------\")\n",
    "    for link in java_links:\n",
    "        print(link)\n",
    "    print(\"Java links end here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3010, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
